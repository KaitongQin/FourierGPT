{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "from run_fft import FFTProcessor\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpectrumData():\n",
    "    def __init__(self, filename):\n",
    "        self.filename = filename\n",
    "        self.spectrum_df = self.read_df()\n",
    "    \n",
    "    def read_df(self):\n",
    "        df = pd.read_csv(self.filename)\n",
    "        return df\n",
    "    \n",
    "    def get_dict(self):\n",
    "        result = {}\n",
    "        unique_sids = self.spectrum_df['sid'].unique()\n",
    "        for sid in unique_sids:\n",
    "            sid_df = self.spectrum_df[self.spectrum_df['sid'] == sid]\n",
    "            result[sid] = {\n",
    "                'freq': sid_df['freq'].values,\n",
    "                'power': sid_df['power'].values\n",
    "            }\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_pair(x_human: dict, x_model: dict, k_freq: int = 10, eps = 0.0, higher = 'model'):\n",
    "    \"\"\"\n",
    "    0 for human, 1 for model\n",
    "    \"\"\"\n",
    "    assert x_human.keys() == x_model.keys()\n",
    "    correct = 0\n",
    "    for sid in x_human.keys():\n",
    "        pow_human = x_human[sid]['power']\n",
    "        pow_model = x_model[sid]['power']\n",
    "        # If higher_spectrum == 'model'\n",
    "        # Hypothesis: pow_samp > pow_orig for k_freq freqs, i.e., Human > Model\n",
    "        if higher == 'model':\n",
    "            if np.sum(pow_model[:k_freq]) - np.sum(pow_human[:k_freq]) > eps:\n",
    "                correct += 1\n",
    "        else:\n",
    "            if np.sum(pow_model[:k_freq]) - np.sum(pow_human[:k_freq]) < eps:\n",
    "                correct += 1\n",
    "    return correct / len(x_human)\n",
    "\n",
    "def select_k(human: dict, model: dict, higher: str):\n",
    "    best_k, best_acc = None, 0.0\n",
    "    for k in range(1, 500):\n",
    "        acc = classify_pair(human, model, k_freq=k, higher=higher)\n",
    "        if acc > best_acc:\n",
    "            best_acc = acc\n",
    "            best_k = k\n",
    "    return best_k, best_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = ['pubmed', 'writing', 'xsum']\n",
    "models = ['gpt-4', 'gpt-3.5', 'gpt-3']\n",
    "labels = ['original', 'sampled']\n",
    "generated_models = ['bigram', 'gpt2xl', 'mistral']\n",
    "type = 'dwt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pubmed:\n",
      "    gpt-4:\n",
      "        bigram:\n",
      "            9: 0.6133\n",
      "        gpt2xl:\n",
      "            9: 0.9467\n",
      "        mistral:\n",
      "            10: 0.9467\n",
      "    gpt-3.5:\n",
      "        bigram:\n",
      "            6: 0.7467\n",
      "        gpt2xl:\n",
      "            8: 0.6133\n",
      "        mistral:\n",
      "            1: 0.9667\n",
      "    gpt-3:\n",
      "        bigram:\n",
      "            15: 0.6067\n",
      "        gpt2xl:\n",
      "            158: 0.7333\n",
      "        mistral:\n",
      "            42: 0.7400\n",
      "writing:\n",
      "    gpt-4:\n",
      "        bigram:\n",
      "            215: 0.6133\n",
      "        gpt2xl:\n",
      "            258: 0.5800\n",
      "        mistral:\n",
      "            6: 0.9533\n",
      "    gpt-3.5:\n",
      "        bigram:\n",
      "            220: 0.7267\n",
      "        gpt2xl:\n",
      "            255: 0.5867\n",
      "        mistral:\n",
      "            1: 0.9867\n",
      "    gpt-3:\n",
      "        bigram:\n",
      "            220: 0.6867\n",
      "        gpt2xl:\n",
      "            244: 0.6533\n",
      "        mistral:\n",
      "            12: 0.8867\n",
      "xsum:\n",
      "    gpt-4:\n",
      "        bigram:\n",
      "            217: 0.7533\n",
      "        gpt2xl:\n",
      "            222: 0.4800\n",
      "        mistral:\n",
      "            8: 0.7733\n",
      "    gpt-3.5:\n",
      "        bigram:\n",
      "            230: 0.7867\n",
      "        gpt2xl:\n",
      "            1: 0.5067\n",
      "        mistral:\n",
      "            8: 0.9467\n",
      "    gpt-3:\n",
      "        bigram:\n",
      "            215: 0.7733\n",
      "        gpt2xl:\n",
      "            241: 0.6867\n",
      "        mistral:\n",
      "            8: 0.7467\n"
     ]
    }
   ],
   "source": [
    "def classify_pair_with_path(original, sampled, higher='model'):\n",
    "    spec_orig = SpectrumData(original)\n",
    "    x_human = spec_orig.get_dict()\n",
    "    spec_samp = SpectrumData(sampled)\n",
    "    x_model = spec_samp.get_dict()\n",
    "    best_k, best_accuracy = select_k(x_human, x_model, higher=higher)\n",
    "    return best_k, best_accuracy\n",
    "\n",
    "for dataset in datasets:\n",
    "    print(f\"{dataset}:\")\n",
    "    for model in models:\n",
    "        print(f\"    {model}:\")\n",
    "        for generated_model in generated_models:\n",
    "            print(f\"        {generated_model}:\")\n",
    "            original = f\"../data/{dataset}/{dataset}_{model}.original.{generated_model}.nllzs.wavelet_{type}.txt\"\n",
    "            sampled = f\"../data/{dataset}/{dataset}_{model}.sampled.{generated_model}.nllzs.wavelet_{type}.txt\"\n",
    "            best_k, best_accuracy = classify_pair_with_path(original, sampled)\n",
    "            print(f\"            {best_k}: {best_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data/gpt-4/pubmed_gpt-4.original.mistral.nllzs.fftnorm.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m genre \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpubmed\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      2\u001b[0m est_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmistral\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 4\u001b[0m spec_orig \u001b[38;5;241m=\u001b[39m \u001b[43mSpectrumData\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m../data/gpt-4/pubmed_gpt-4.original.\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mest_name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.nllzs.fftnorm.txt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m x_human \u001b[38;5;241m=\u001b[39m spec_orig\u001b[38;5;241m.\u001b[39mget_dict()\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# print(x_orig[0])\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[20], line 4\u001b[0m, in \u001b[0;36mSpectrumData.__init__\u001b[0;34m(self, filename)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, filename):\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilename \u001b[38;5;241m=\u001b[39m filename\n\u001b[0;32m----> 4\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspectrum_df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_df\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[20], line 7\u001b[0m, in \u001b[0;36mSpectrumData.read_df\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mread_df\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m----> 7\u001b[0m     df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m df\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp/lib/python3.10/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp/lib/python3.10/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data/gpt-4/pubmed_gpt-4.original.mistral.nllzs.fftnorm.txt'"
     ]
    }
   ],
   "source": [
    "genre = 'pubmed'\n",
    "est_name = 'mistral'\n",
    "\n",
    "spec_orig = SpectrumData(f'../data/gpt-4/pubmed_gpt-4.original.{est_name}.nllzs.fftnorm.txt')\n",
    "x_human = spec_orig.get_dict()\n",
    "# print(x_orig[0])\n",
    "\n",
    "spec_samp = SpectrumData(f'../data/gpt-4/pubmed_gpt-4.sampled.{est_name}.nllzs.fftnorm.txt')\n",
    "x_model = spec_samp.get_dict()\n",
    "\n",
    "acc = classify_pair(x_human, x_model, k_freq=3, eps=0.0)\n",
    "print(acc)\n",
    "\n",
    "best_k, best_acc = select_k(x_human, x_model, higher='model')\n",
    "print(f'{genre}, {est_name}, best_k={best_k}, best_acc={best_acc}')\n",
    "\n",
    "# pubmed, mistral, k=10, 0.867\n",
    "# pubmed, mistral, k=3, 0.90\n",
    "# pubmed, mistral, k=5, 0.887"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT-4:\n",
      "pubmed, mistral, best_k=3, best_acc=0.9000, higher=model\n",
      "pubmed, gpt2xl, best_k=3, best_acc=0.9133, higher=model\n",
      "writing, mistral, best_k=4, best_acc=0.7667, higher=model\n",
      "writing, gpt2xl, best_k=23, best_acc=0.8467, higher=human\n",
      "xsum, mistral, best_k=48, best_acc=0.6533, higher=human\n",
      "xsum, gpt2xl, best_k=29, best_acc=0.8733, higher=human\n"
     ]
    }
   ],
   "source": [
    "# Eval loop for GPT-4\n",
    "print('GPT-4:')\n",
    "\n",
    "for genre in ['pubmed', 'writing', 'xsum']:\n",
    "    for est_name in ['mistral', 'llama', 'gpt2xl', 'gpt2lg', 'gpt2md', 'gpt2']:\n",
    "        orig_filename = f'../data/gpt-4/{genre}_gpt-4.original.{est_name}.nllzs.fftnorm.txt'\n",
    "        samp_filename = f'../data/gpt-4/{genre}_gpt-4.sampled.{est_name}.nllzs.fftnorm.txt'\n",
    "        if not os.path.exists(orig_filename) or not os.path.exists(samp_filename):\n",
    "            continue\n",
    "        spec_orig = SpectrumData(orig_filename)\n",
    "        x_human = spec_orig.get_dict()\n",
    "        spec_samp = SpectrumData(samp_filename)\n",
    "        x_model = spec_samp.get_dict()\n",
    "\n",
    "        best_k_1, best_acc_1 = select_k(x_human, x_model, higher='human')\n",
    "        best_k_2, best_acc_2 = select_k(x_human, x_model, higher='model')\n",
    "        if best_acc_1 > best_acc_2:\n",
    "            best_k = best_k_1\n",
    "            best_acc = best_acc_1\n",
    "            higher = 'human'\n",
    "        else:\n",
    "            best_k = best_k_2\n",
    "            best_acc = best_acc_2\n",
    "            higher = 'model'\n",
    "        print(f'{genre}, {est_name}, best_k={best_k}, best_acc={best_acc:.4f}, higher={higher}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT-3.5:\n",
      "pubmed, mistral, best_k=2, best_acc=0.9467, higher=model\n",
      "pubmed, gpt2xl, best_k=10, best_acc=0.6200, higher=model\n",
      "writing, mistral, best_k=3, best_acc=0.9200, higher=model\n",
      "writing, gpt2xl, best_k=30, best_acc=0.8533, higher=human\n",
      "xsum, mistral, best_k=4, best_acc=0.9067, higher=model\n",
      "xsum, gpt2xl, best_k=24, best_acc=0.9200, higher=human\n"
     ]
    }
   ],
   "source": [
    "# Eval loop for GPT-3.5\n",
    "print('GPT-3.5:')\n",
    "\n",
    "for genre in ['pubmed', 'writing', 'xsum']:\n",
    "    for est_name in ['mistral', 'llama', 'gpt2xl', 'gpt2lg', 'gpt2md', 'gpt2']:\n",
    "        orig_filename = f'../data/gpt-3.5/{genre}_gpt-3.5-turbo.original.{est_name}.nllzs.fftnorm.txt'\n",
    "        samp_filename = f'../data/gpt-3.5/{genre}_gpt-3.5-turbo.sampled.{est_name}.nllzs.fftnorm.txt'\n",
    "        if not os.path.exists(orig_filename) or not os.path.exists(samp_filename):\n",
    "            continue\n",
    "        spec_orig = SpectrumData(orig_filename)\n",
    "        x_human = spec_orig.get_dict()\n",
    "        spec_samp = SpectrumData(samp_filename)\n",
    "        x_model = spec_samp.get_dict()\n",
    "\n",
    "        best_k_1, best_acc_1 = select_k(x_human, x_model, higher='human')\n",
    "        best_k_2, best_acc_2 = select_k(x_human, x_model, higher='model')\n",
    "        if best_acc_1 > best_acc_2:\n",
    "            best_k = best_k_1\n",
    "            best_acc = best_acc_1\n",
    "            higher = 'human'\n",
    "        else:\n",
    "            best_k = best_k_2\n",
    "            best_acc = best_acc_2\n",
    "            higher = 'model'\n",
    "        print(f'{genre}, {est_name}, best_k={best_k}, best_acc={best_acc:.4f}, higher={higher}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT-3:\n",
      "pubmed, mistral, best_k=5, best_acc=0.6867, higher=model\n",
      "pubmed, gpt2xl, best_k=10, best_acc=0.6600, higher=model\n",
      "writing, mistral, best_k=10, best_acc=0.7200, higher=model\n",
      "writing, gpt2xl, best_k=40, best_acc=0.6000, higher=model\n",
      "xsum, mistral, best_k=2, best_acc=0.5867, higher=model\n",
      "xsum, gpt2xl, best_k=3, best_acc=0.6067, higher=model\n"
     ]
    }
   ],
   "source": [
    "# Eval loop for Davinci\n",
    "print('GPT-3:')\n",
    "\n",
    "for genre in ['pubmed', 'writing', 'xsum']:\n",
    "    for est_name in ['mistral', 'llama', 'gpt2xl', 'gpt2lg', 'gpt2md', 'gpt2']:\n",
    "        orig_filename = f'../data/davinci/{genre}_davinci.original.{est_name}.nllzs.fftnorm.txt'\n",
    "        samp_filename = f'../data/davinci/{genre}_davinci.sampled.{est_name}.nllzs.fftnorm.txt'\n",
    "        if not os.path.exists(orig_filename) or not os.path.exists(samp_filename):\n",
    "            continue\n",
    "        spec_orig = SpectrumData(orig_filename)\n",
    "        x_human = spec_orig.get_dict()\n",
    "        spec_samp = SpectrumData(samp_filename)\n",
    "        x_model = spec_samp.get_dict()\n",
    "\n",
    "        best_k_1, best_acc_1 = select_k(x_human, x_model, higher='human')\n",
    "        best_k_2, best_acc_2 = select_k(x_human, x_model, higher='model')\n",
    "        if best_acc_1 > best_acc_2:\n",
    "            best_k = best_k_1\n",
    "            best_acc = best_acc_1\n",
    "            higher = 'human'\n",
    "        else:\n",
    "            best_k = best_k_2\n",
    "            best_acc = best_acc_2\n",
    "            higher = 'model'\n",
    "        print(f'{genre}, {est_name}, best_k={best_k}, best_acc={best_acc:.4f}, higher={higher}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate classification on bigram as estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bigram GPT-4:\n",
      "pubmed, bigram, best_k=12, best_acc=0.6533, higher=human\n",
      "writing, bigram, best_k=28, best_acc=0.8800, higher=human\n",
      "xsum, bigram, best_k=34, best_acc=0.7667, higher=human\n"
     ]
    }
   ],
   "source": [
    "print('bigram GPT-4:')\n",
    "for genre in ['pubmed', 'writing', 'xsum']:\n",
    "    for est_name in ['bigram']:\n",
    "        orig_filename = f'../data/gpt-4/bigram/fftnorm/{genre}_gpt-4.original.{est_name}.fftnorm.txt'\n",
    "        samp_filename = f'../data/gpt-4/bigram/fftnorm/{genre}_gpt-4.sampled.{est_name}.fftnorm.txt'\n",
    "        if not os.path.exists(orig_filename) or not os.path.exists(samp_filename):\n",
    "            continue\n",
    "        spec_orig = SpectrumData(orig_filename)\n",
    "        x_human = spec_orig.get_dict()\n",
    "        spec_samp = SpectrumData(samp_filename)\n",
    "        x_model = spec_samp.get_dict()\n",
    "\n",
    "        best_k_1, best_acc_1 = select_k(x_human, x_model, higher='human')\n",
    "        best_k_2, best_acc_2 = select_k(x_human, x_model, higher='model')\n",
    "        if best_acc_1 > best_acc_2:\n",
    "            best_k = best_k_1\n",
    "            best_acc = best_acc_1\n",
    "            higher = 'human'\n",
    "        else:\n",
    "            best_k = best_k_2\n",
    "            best_acc = best_acc_2\n",
    "            higher = 'model'\n",
    "        print(f'{genre}, {est_name}, best_k={best_k}, best_acc={best_acc:.4f}, higher={higher}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bigram GPT-3.5:\n",
      "pubmed, bigram, best_k=3, best_acc=0.6267, higher=model\n",
      "writing, bigram, best_k=30, best_acc=0.9067, higher=human\n",
      "xsum, bigram, best_k=44, best_acc=0.7800, higher=human\n"
     ]
    }
   ],
   "source": [
    "print('bigram GPT-3.5:')\n",
    "for genre in ['pubmed', 'writing', 'xsum']:\n",
    "    for est_name in ['bigram']:\n",
    "        orig_filename = f'../data/gpt-3.5/bigram/fftnorm/{genre}_gpt-3.5-turbo.original.{est_name}.fftnorm.txt'\n",
    "        samp_filename = f'../data/gpt-3.5/bigram/fftnorm/{genre}_gpt-3.5-turbo.sampled.{est_name}.fftnorm.txt'\n",
    "        if not os.path.exists(orig_filename) or not os.path.exists(samp_filename):\n",
    "            continue\n",
    "        spec_orig = SpectrumData(orig_filename)\n",
    "        x_human = spec_orig.get_dict()\n",
    "        spec_samp = SpectrumData(samp_filename)\n",
    "        x_model = spec_samp.get_dict()\n",
    "\n",
    "        best_k_1, best_acc_1 = select_k(x_human, x_model, higher='human')\n",
    "        best_k_2, best_acc_2 = select_k(x_human, x_model, higher='model')\n",
    "        if best_acc_1 > best_acc_2:\n",
    "            best_k = best_k_1\n",
    "            best_acc = best_acc_1\n",
    "            higher = 'human'\n",
    "        else:\n",
    "            best_k = best_k_2\n",
    "            best_acc = best_acc_2\n",
    "            higher = 'model'\n",
    "        print(f'{genre}, {est_name}, best_k={best_k}, best_acc={best_acc:.4f}, higher={higher}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bigram GPT-3:\n",
      "pubmed, bigram, best_k=8, best_acc=0.6733, higher=model\n",
      "writing, bigram, best_k=8, best_acc=0.5733, higher=human\n",
      "xsum, bigram, best_k=26, best_acc=0.6400, higher=model\n"
     ]
    }
   ],
   "source": [
    "print('bigram GPT-3:')\n",
    "for genre in ['pubmed', 'writing', 'xsum']:\n",
    "    for est_name in ['bigram']:\n",
    "        orig_filename = f'../data/davinci/bigram/fftnorm/{genre}_davinci.original.{est_name}.fftnorm.txt'\n",
    "        samp_filename = f'../data/davinci/bigram/fftnorm/{genre}_davinci.sampled.{est_name}.fftnorm.txt'\n",
    "        if not os.path.exists(orig_filename) or not os.path.exists(samp_filename):\n",
    "            continue\n",
    "        spec_orig = SpectrumData(orig_filename)\n",
    "        x_human = spec_orig.get_dict()\n",
    "        spec_samp = SpectrumData(samp_filename)\n",
    "        x_model = spec_samp.get_dict()\n",
    "\n",
    "        best_k_1, best_acc_1 = select_k(x_human, x_model, higher='human')\n",
    "        best_k_2, best_acc_2 = select_k(x_human, x_model, higher='model')\n",
    "        if best_acc_1 > best_acc_2:\n",
    "            best_k = best_k_1\n",
    "            best_acc = best_acc_1\n",
    "            higher = 'human'\n",
    "        else:\n",
    "            best_k = best_k_2\n",
    "            best_acc = best_acc_2\n",
    "            higher = 'model'\n",
    "        print(f'{genre}, {est_name}, best_k={best_k}, best_acc={best_acc:.4f}, higher={higher}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification on chop = 50, 100, 150 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chop length:\n",
      "writing, chop=50, best_k=8, best_acc=0.6800, higher=human\n",
      "writing, chop=100, best_k=13, best_acc=0.8200, higher=human\n",
      "writing, chop=150, best_k=19, best_acc=0.8933, higher=human\n",
      "xsum, chop=50, best_k=5, best_acc=0.6533, higher=human\n",
      "xsum, chop=100, best_k=16, best_acc=0.7533, higher=human\n",
      "xsum, chop=150, best_k=21, best_acc=0.7867, higher=human\n"
     ]
    }
   ],
   "source": [
    "print('Chop length:')\n",
    "\n",
    "for genre in ['writing', 'xsum']:\n",
    "    for chop_k in [50, 100, 150]:\n",
    "        est_name = 'gpt2xl'\n",
    "        orig_filename = f'../data/short/{genre}_gpt-4.original.{est_name}.chop{chop_k}.nllzs.fftnorm.txt'\n",
    "        samp_filename = f'../data/short/{genre}_gpt-4.sampled.{est_name}.chop{chop_k}.nllzs.fftnorm.txt'\n",
    "        if not os.path.exists(orig_filename) or not os.path.exists(samp_filename):\n",
    "            continue\n",
    "        spec_orig = SpectrumData(orig_filename)\n",
    "        x_human = spec_orig.get_dict()\n",
    "        spec_samp = SpectrumData(samp_filename)\n",
    "        x_model = spec_samp.get_dict()\n",
    "\n",
    "        best_k_1, best_acc_1 = select_k(x_human, x_model, higher='human')\n",
    "        best_k_2, best_acc_2 = select_k(x_human, x_model, higher='model')\n",
    "        if best_acc_1 > best_acc_2:\n",
    "            best_k = best_k_1\n",
    "            best_acc = best_acc_1\n",
    "            higher = 'human'\n",
    "        else:\n",
    "            best_k = best_k_2\n",
    "            best_acc = best_acc_2\n",
    "            higher = 'model'\n",
    "        print(f'{genre}, chop={chop_k}, best_k={best_k}, best_acc={best_acc:.4f}, higher={higher}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring classifier with two thresholds, `k_low`, `k_high`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_pair(x_human: dict, x_model: dict, k_freq: int = 10, eps = 0.0, higher = 'model'):\n",
    "    \"\"\"\n",
    "    0 for human, 1 for model\n",
    "    \"\"\"\n",
    "    assert x_human.keys() == x_model.keys()\n",
    "    correct = 0\n",
    "    for sid in x_human.keys():\n",
    "        pow_human = x_human[sid]['power']\n",
    "        pow_model = x_model[sid]['power']\n",
    "        # If higher_spectrum == 'model'\n",
    "        # Hypothesis: pow_samp > pow_orig for k_freq freqs, i.e., Human > Model\n",
    "        if higher == 'model':\n",
    "            if np.sum(pow_model[:k_freq]) - np.sum(pow_human[:k_freq]) > eps:\n",
    "                correct += 1\n",
    "        else:\n",
    "            if np.sum(pow_model[:k_freq]) - np.sum(pow_human[:k_freq]) < eps:\n",
    "                correct += 1\n",
    "    return correct / len(x_human)\n",
    "\n",
    "def select_k(human: dict, model: dict, higher: str):\n",
    "    best_k, best_acc = None, 0.0\n",
    "    for k in range(1, 51):\n",
    "        acc = classify_pair(human, model, k_freq=k, higher=higher)\n",
    "        if acc > best_acc:\n",
    "            best_acc = acc\n",
    "            best_k = k\n",
    "    return best_k, best_acc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
